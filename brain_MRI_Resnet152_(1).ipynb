{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4Ywb1HzTfoF"
      },
      "source": [
        "# Mounting Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjAcUHr6ScU9",
        "outputId": "7b182991-7fe3-4a0d-8f7a-34a193c774a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFmLzP4mTjzX"
      },
      "source": [
        "---\n",
        "# Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "50u5EJX_Sj-N"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms, models\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpr_fG-eapOv"
      },
      "source": [
        "---\n",
        "# Copying Dataste to colab runtime\n",
        "\n",
        "Copying the dataset: We use the function shutil.copytree to duplicate the entire directory from Google Drive to our local file system in Colab. This function copies the folder structure along with all files inside, preserving the hierarchy of subfolders such as “yes” and “no.”\n",
        "\n",
        "Local dataset path: We are storing the dataset in /content/brain_tumor_dataset within Colab. Saving data locally in Colab can often be faster than reading directly from Drive because local file operations are quicker and do not require the overhead of synchronizing with Google Drive.\n",
        "\n",
        "Cleaning up: Before we copy, we check whether a folder named brain_tumor_dataset already exists locally. If it does, we remove that folder using shutil.rmtree. This helps prevent file mix-ups or errors that might occur if two folders have the same name.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1P8SnV-ubnsG",
        "outputId": "4225460f-1b15-4fb1-adf7-60a9e4aa9314"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset copied to local Colab folder: /content/brain_tumor_dataset\n",
            "Classes found: ['no', 'yes']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# The original dataset path on Google Drive, containing 'no' and 'yes' subfolders\n",
        "drive_dataset_path = \"/content/drive/MyDrive/MRI_DL_Dataset/brain_tumor_dataset\"\n",
        "\n",
        "# The local path in Colab where we will copy the dataset\n",
        "local_dataset_path = \"/content/brain_tumor_dataset\"\n",
        "\n",
        "# If a local folder with the same name already exists, we remove it to avoid duplication\n",
        "if os.path.exists(local_dataset_path):\n",
        "    shutil.rmtree(local_dataset_path)\n",
        "\n",
        "# We copy the entire directory from Google Drive to Colab's local file system\n",
        "shutil.copytree(drive_dataset_path, local_dataset_path)\n",
        "\n",
        "# We print a confirmation message and list the subfolders (classes) that were copied\n",
        "print(\"Dataset copied to local Colab folder:\", local_dataset_path)\n",
        "print(\"Classes found:\", os.listdir(local_dataset_path))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psOZeWW1b_Jg"
      },
      "source": [
        "---\n",
        "# Step 2: Rename the Files\n",
        "\n",
        "making sure our filenames are consistent is very important , as you can see below , the file names for 'no' are in different formats from the 'yes' files so let us"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSLS4pgkcFhm",
        "outputId": "58fcd0b4-a8c3-4fee-d912-e9407dac5bab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> ORIGINAL FILE NAMES <<<\n",
            "\n",
            "Class 'no' has 98 files.\n",
            "Sample file names: ['no 1.jpg', 'no 94.jpg', '23 no.jpg', '37 no.jpg', 'no 89.jpg']\n",
            "\n",
            "Class 'yes' has 155 files.\n",
            "Sample file names: ['Y1.jpg', 'Y92.png', 'Y58.JPG', 'Y107.jpg', 'Y49.JPG']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Path to the local copy of the dataset in Colab (two class folders: \"no\" and \"yes\")\n",
        "local_dataset_path = \"/content/brain_tumor_dataset\"\n",
        "\n",
        "print(\">>> ORIGINAL FILE NAMES <<<\")\n",
        "class_dirs = [\"no\", \"yes\"]  # Our two classes\n",
        "\n",
        "# We iterate over each class folder and display a few file names\n",
        "for class_dir in class_dirs:\n",
        "    folder_path = os.path.join(local_dataset_path, class_dir)\n",
        "    if os.path.isdir(folder_path):\n",
        "        files = os.listdir(folder_path)\n",
        "        print(f\"\\nClass '{class_dir}' has {len(files)} files.\")\n",
        "        # Show up to the first 5 file names for a quick preview\n",
        "        print(\"Sample file names:\", files[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMHMROdocF4h"
      },
      "source": [
        "Why rename the files? We want a consistent naming convention so that all images in the “no” folder start with ‘N’ and all images in the “yes” folder start with ‘Y.’ This helps keep things organized and makes it easier to visually confirm which class an image belongs to when browsing files.\n",
        "\n",
        "Checking file types: We use os.path.isfile to ensure we only rename actual image files and not subdirectories or other non-file entries.\n",
        "\n",
        "Prepending ‘N_’ or ‘Y_’: If a file in the “no” folder does not already start with an N, we rename it to begin with N_. Similarly, if a file in the “yes” folder does not start with a Y, we rename it to begin with Y_. This step is repeated for every file in each subfolder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6d6KJrZecGRm",
        "outputId": "aef317d8-5ad7-4a9a-b7ea-b14610e98c1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> All files have been systematically renamed! <<<\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# The local dataset path in Colab\n",
        "local_dataset_path = \"/content/brain_tumor_dataset\"\n",
        "\n",
        "# The two class folders: \"no\" and \"yes\"\n",
        "class_dirs = [\"no\", \"yes\"]\n",
        "\n",
        "# We iterate over each class folder\n",
        "for class_dir in class_dirs:\n",
        "    folder_path = os.path.join(local_dataset_path, class_dir)\n",
        "\n",
        "    # Gather all the files in this folder\n",
        "    files = os.listdir(folder_path)\n",
        "    files = [f for f in files if os.path.isfile(os.path.join(folder_path, f))]\n",
        "\n",
        "    # Enumerate the files so we have an index (i) and a filename (file_name)\n",
        "    for i, file_name in enumerate(files):\n",
        "        old_file_path = os.path.join(folder_path, file_name)\n",
        "\n",
        "        # We'll create a new file name with a zero-padded index (e.g., 001, 002...)\n",
        "        # If the folder is 'no', we use 'N'; if 'yes', we use 'Y'\n",
        "        if class_dir == \"no\":\n",
        "            new_file_name = f\"N{(i+1):03d}.jpg\"  # e.g. N001.jpg, N002.jpg, ...\n",
        "        else:\n",
        "            new_file_name = f\"Y{(i+1):03d}.jpg\"  # e.g. Y001.jpg, Y002.jpg, ...\n",
        "\n",
        "        # Build the full path for the new filename\n",
        "        new_file_path = os.path.join(folder_path, new_file_name)\n",
        "\n",
        "        # Rename the file on disk\n",
        "        os.rename(old_file_path, new_file_path)\n",
        "\n",
        "print(\">>> All files have been systematically renamed! <<<\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aq8lMHmsd2Ua"
      },
      "source": [
        "## Verifying the names of files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Y6R7s8Zd9U0",
        "outputId": "7b095f1f-3f66-4254-b874-cc1f1aeef1ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> Renamed files: Quick Preview <<<\n",
            "\n",
            "Class 'no' has 98 renamed files.\n",
            "Sample file names: ['N001.jpg', 'N002.jpg', 'N003.jpg', 'N004.jpg', 'N005.jpg']\n",
            "\n",
            "Class 'yes' has 151 renamed files.\n",
            "Sample file names: ['Y001.jpg', 'Y002.jpg', 'Y003.jpg', 'Y004.jpg', 'Y005.jpg']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "local_dataset_path = \"/content/brain_tumor_dataset\"\n",
        "class_dirs = [\"no\", \"yes\"]\n",
        "\n",
        "print(\">>> Renamed files: Quick Preview <<<\")\n",
        "for class_dir in class_dirs:\n",
        "    folder_path = os.path.join(local_dataset_path, class_dir)\n",
        "    renamed_files = os.listdir(folder_path)\n",
        "    renamed_files = [f for f in renamed_files if os.path.isfile(os.path.join(folder_path, f))]\n",
        "\n",
        "    # Sort them just to see them in ascending numerical order\n",
        "    renamed_files.sort()\n",
        "\n",
        "    print(f\"\\nClass '{class_dir}' has {len(renamed_files)} renamed files.\")\n",
        "    # Show the first few renamed filenames for confirmation\n",
        "    print(\"Sample file names:\", renamed_files[:5])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAmflBOheEi8"
      },
      "source": [
        "After renaming, it’s good practice to verify that the files have indeed been renamed correctly:\n",
        "\n",
        "We list the files again in each class folder.\n",
        "\n",
        "We sort the filenames so that they appear in ascending order (i.e., N001, N002, N003...). This step makes it easy to see if they match the expected pattern.\n",
        "\n",
        "We print out the first few filenames to confirm that they all have the desired Nxxx or Yxxx format.\n",
        "\n",
        "By doing this, we can be certain our renaming step worked as intended and that our dataset now has a consistent, organized naming convention.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IP4VjQLFgIzd"
      },
      "source": [
        "---\n",
        "# Balancing the dataset and SPlitting into Train Test Val\n",
        "\n",
        "We previously observed that the original dataset has an **unequal number of images in each class**. This imbalance could cause a** model to learn biases, favoring the class with more examples**. To address this we  decided on a strategy that enforces an **equal number of images from each class in the training set** (for example, selecting the same number of “yes” and “no” images) while distributing leftover images into validation and test sets. This approach ensures that the classifier is not inherently skewed toward any particular class, leading to more robust and fair performance across the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koYMyPEFgnmP",
        "outputId": "2718587e-3c9e-48d0-dbf0-807475f91072"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class Distribution:\n",
            "  no: 98 images\n",
            "  yes: 151 images\n",
            "\n",
            "Observation: The dataset is not balanced.\n",
            "The difference between classes is 53 images.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Assume there are two class folders: \"no\" and \"yes\"\n",
        "dataset_path = \"/content/brain_tumor_dataset\"\n",
        "class_dirs = [\"no\", \"yes\"]\n",
        "\n",
        "counts = {}\n",
        "total_images = 0\n",
        "\n",
        "# Count the number of images in each class\n",
        "for class_dir in class_dirs:\n",
        "    folder_path = os.path.join(dataset_path, class_dir)\n",
        "    files = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
        "    counts[class_dir] = len(files)\n",
        "    total_images += len(files)\n",
        "\n",
        "# Print the distribution\n",
        "print(\"Class Distribution:\")\n",
        "for class_dir in class_dirs:\n",
        "    print(f\"  {class_dir}: {counts[class_dir]} images\")\n",
        "\n",
        "# Check balance\n",
        "if counts[\"no\"] != counts[\"yes\"]:\n",
        "    print(\"\\nObservation: The dataset is not balanced.\")\n",
        "    diff = abs(counts[\"no\"] - counts[\"yes\"])\n",
        "    print(f\"The difference between classes is {diff} images.\")\n",
        "else:\n",
        "    print(\"\\nObservation: The dataset is balanced.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQ3QpQ-iXlja"
      },
      "source": [
        "---\n",
        "## Spliting Paths\n",
        "\n",
        "### Define Paths and Parameters\n",
        "- The dataset is located in `/content/brain_tumor_dataset`, and the split data will be saved in `/content/split_balanced`.\n",
        "- The code is set to choose **75 images per class** for the training set. This fixed number helps ensure that both the “no” and “yes” classes are equally represented in training, reducing any bias.\n",
        "\n",
        "### Clean-Up and Setup\n",
        "- Any existing split folder is deleted to start fresh.\n",
        "- New folders for **train**, **val**, and **test** are created.\n",
        "\n",
        "### Splitting Logic\n",
        "- For each class, the code shuffles the list of image files to randomize the selection.\n",
        "- It then selects up to **75 images** for the training set.\n",
        "- The remaining images (if any) are split equally into validation and test sets.\n",
        "\n",
        "### Copying Files\n",
        "- The files are copied (not moved) into subfolders (e.g., `train/no`, `train/yes`, `val/no`, etc.), ensuring that the training set is balanced.\n",
        "\n",
        "### Summary Output\n",
        "- A summary is printed for each class, showing the total number of images and the counts in the train, validation, and test splits.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frfj_plOZvuE",
        "outputId": "5d7cfea1-af09-4384-c1a1-f52011287109"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class 'no' splitting summary:\n",
            "  Total images: 98\n",
            "  Train: 75\n",
            "  Val:   11\n",
            "  Test:  12\n",
            "\n",
            "Class 'yes' splitting summary:\n",
            "  Total images: 151\n",
            "  Train: 75\n",
            "  Val:   38\n",
            "  Test:  38\n",
            "\n",
            "Splitting complete!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "# Define the local path of the renamed dataset in Colab\n",
        "local_dataset_path = \"/content/brain_tumor_dataset\"\n",
        "\n",
        "# Define the output folder where the split data will be stored\n",
        "local_output_path = \"/content/split_balanced\"\n",
        "\n",
        "# Set the number of training images per class (75 in this case)\n",
        "train_count_per_class = 75\n",
        "\n",
        "# Set the ratios for splitting leftover images: 50% for validation, 50% for test\n",
        "val_ratio = 0.5\n",
        "test_ratio = 0.5  # not explicitly used since test gets the remainder\n",
        "\n",
        "# List the class names (assumed to be two classes: \"no\" and \"yes\")\n",
        "class_names = [\"no\", \"yes\"]\n",
        "\n",
        "# Remove any existing output folder to ensure a clean split\n",
        "if os.path.exists(local_output_path):\n",
        "    shutil.rmtree(local_output_path)\n",
        "\n",
        "# Create the main split directories (train, val, and test)\n",
        "for split in [\"train\", \"val\", \"test\"]:\n",
        "    os.makedirs(os.path.join(local_output_path, split), exist_ok=True)\n",
        "\n",
        "# Iterate through each class folder and perform the split\n",
        "for class_name in class_names:\n",
        "    class_dir = os.path.join(local_dataset_path, class_name)\n",
        "    # List only files (ignoring subdirectories)\n",
        "    all_files = [f for f in os.listdir(class_dir) if os.path.isfile(os.path.join(class_dir, f))]\n",
        "\n",
        "    # Shuffle the list to ensure randomness in splitting\n",
        "    random.shuffle(all_files)\n",
        "\n",
        "    # Select up to 75 images for the training set (or all if fewer exist)\n",
        "    train_files = all_files[:min(train_count_per_class, len(all_files))]\n",
        "\n",
        "    # The remaining images will be split equally between validation and test\n",
        "    leftover = all_files[min(train_count_per_class, len(all_files)):]\n",
        "    val_count = int(len(leftover) * val_ratio)\n",
        "    val_files = leftover[:val_count]\n",
        "    test_files = leftover[val_count:]\n",
        "\n",
        "    # Create subdirectories for each class within train, val, and test folders\n",
        "    for split in [\"train\", \"val\", \"test\"]:\n",
        "        os.makedirs(os.path.join(local_output_path, split, class_name), exist_ok=True)\n",
        "\n",
        "    # Helper function to copy files to the designated split folder\n",
        "    def copy_files(file_list, split):\n",
        "        for f in file_list:\n",
        "            src = os.path.join(class_dir, f)\n",
        "            dst = os.path.join(local_output_path, split, class_name, f)\n",
        "            shutil.copy2(src, dst)\n",
        "\n",
        "    # Copy the files into the corresponding folders\n",
        "    copy_files(train_files, \"train\")\n",
        "    copy_files(val_files, \"val\")\n",
        "    copy_files(test_files, \"test\")\n",
        "\n",
        "    # Print a summary for each class\n",
        "    print(f\"Class '{class_name}' splitting summary:\")\n",
        "    print(f\"  Total images: {len(all_files)}\")\n",
        "    print(f\"  Train: {len(train_files)}\")\n",
        "    print(f\"  Val:   {len(val_files)}\")\n",
        "    print(f\"  Test:  {len(test_files)}\\n\")\n",
        "\n",
        "print(\"Splitting complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LENfjHX4hZkP"
      },
      "source": [
        "## Verifying the Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBVKA4_JhQH2",
        "outputId": "77b251d4-797c-4757-b85a-11b8e43804db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final split verification:\n",
            "TRAIN | Class 'no': 75 images\n",
            "TRAIN | Class 'yes': 75 images\n",
            "\n",
            "VAL | Class 'no': 11 images\n",
            "VAL | Class 'yes': 38 images\n",
            "\n",
            "TEST | Class 'no': 12 images\n",
            "TEST | Class 'yes': 38 images\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "splits = [\"train\", \"val\", \"test\"]\n",
        "class_names = [\"no\", \"yes\"]\n",
        "\n",
        "print(\"Final split verification:\")\n",
        "for split in splits:\n",
        "    for class_name in class_names:\n",
        "        split_dir = os.path.join(local_output_path, split, class_name)\n",
        "        file_list = [f for f in os.listdir(split_dir) if os.path.isfile(os.path.join(split_dir, f))]\n",
        "        print(f\"{split.upper()} | Class '{class_name}': {len(file_list)} images\")\n",
        "    print()  # Blank line for readability\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRZMx0_kie0d"
      },
      "source": [
        "---\n",
        "# FINAL SUMMARY OF WHAT WE DID AND HOW OT START\n",
        "\n",
        "## Preprocessing and Folder Structure\n",
        "\n",
        "### Folder Structure\n",
        "\n",
        "After splitting the dataset, the directory structure is organized as follows:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "Fg0eS1uGhqii",
        "outputId": "5c1c346b-628a-43fa-d72c-83ab6b181855"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid character '├' (U+251C) (<ipython-input-12-4af7d8efa0f0>, line 2)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-4af7d8efa0f0>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    ├── train/\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character '├' (U+251C)\n"
          ]
        }
      ],
      "source": [
        "/content/split_balanced/\n",
        "├── train/\n",
        "│   ├── no/     # 75 balanced images from the \"no\" class for training\n",
        "│   └── yes/    # 75 balanced images from the \"yes\" class for training\n",
        "├── val/\n",
        "│   ├── no/     # A portion of the remaining \"no\" images for validation\n",
        "│   └── yes/    # A portion of the remaining \"yes\" images for validation\n",
        "└── test/\n",
        "    ├── no/     # The remaining \"no\" images for testing\n",
        "    └── yes/    # The remaining \"yes\" images for testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mVRcGvwjQpO"
      },
      "source": [
        "\n",
        "### Preprocessing Explanation\n",
        "\n",
        "1. **Image Resizing**:  \n",
        "   All images are resized to a fixed size (for example, 224x224 pixels). This step is essential because most deep learning models require input images of the same dimensions. Resizing ensures that the images fit the model's expected input size.\n",
        "\n",
        "2. **Data Augmentation (for Training Data)**:  \n",
        "   To increase the diversity of the training dataset and help the model generalize better, random horizontal and vertical flips are applied. These transformations simulate different perspectives of the images and reduce the risk of overfitting. Note that such augmentations are applied only to the training data—not to validation or test data—to keep those sets consistent.\n",
        "\n",
        "3. **Normalization**:  \n",
        "   Images are normalized using predefined mean and standard deviation values (commonly the ImageNet statistics: mean = [0.485, 0.456, 0.406] and std = [0.229, 0.224, 0.225]). Normalization scales pixel values to a standard range, which speeds up the training process and helps the model converge more effectively.\n",
        "\n",
        "### How to Start Training Models\n",
        "\n",
        "1. **Setting Up Data Loaders**:  \n",
        "   With the folder structure in place, you can use PyTorch’s `datasets.ImageFolder` to load the images from the `train`, `val`, and `test` directories. The data loaders batch the images and apply the defined transformations (resizing, augmentation, normalization) on the fly.\n",
        "\n",
        "2. **Model Architecture**:  \n",
        "   A popular approach is to use a pre-trained model (like ResNet18 from `torchvision.models`) and modify its final fully-connected layer to output the correct number of classes (2, in this case). Pre-trained models already have learned useful features, which can speed up the training process when fine-tuned on your dataset.\n",
        "\n",
        "3. **Loss Function and Optimizer**:  \n",
        "   Use the CrossEntropyLoss as the loss function, which is suitable for classification tasks. An optimizer such as Adam is then used to update the model’s weights based on the loss. This combination is standard practice in many image classification projects.\n",
        "\n",
        "4. **Training Loop**:  \n",
        "   Write a training loop that:\n",
        "   - Iterates over the training data in batches.\n",
        "   - Performs a forward pass to compute predictions.\n",
        "   - Computes the loss between the predictions and the true labels.\n",
        "   - Executes a backward pass to compute gradients.\n",
        "   - Updates the model parameters using the optimizer.\n",
        "   During training, the model is evaluated on the validation set to monitor performance and adjust hyperparameters if needed.\n",
        "\n",
        "5. **Testing**:  \n",
        "   After training, the model’s performance is evaluated on the test set. This step ensures that the model generalizes well to unseen data. Metrics like accuracy, precision, recall, and a confusion matrix can be computed to understand the model's strengths and weaknesses.\n",
        "\n",
        "### Summary\n",
        "\n",
        "- **Folder Structure**: The dataset is split into `train`, `val`, and `test` folders, with each split containing subfolders for the \"no\" and \"yes\" classes. The training set is balanced with exactly 75 images from each class.\n",
        "- **Preprocessing**: Images are resized to a standard size, augmented (only for training) with random flips to enhance generalization, and normalized using standard values.\n",
        "- **Training Setup**: Data loaders facilitate batch processing, a pre-trained model (e.g., ResNet18) is fine-tuned on the dataset, and a training loop is used to update model parameters based on the loss computed from predictions.\n",
        "- **Evaluation**: Finally, testing on a separate test set ensures that the model performs well on new, unseen data.\n",
        "\n",
        "This comprehensive process, explained in detailed yet straightforward language, ensures that even a beginner can understand how to preprocess the data, set up the folder structure, and start training a model on the balanced dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zpNpo0ByYFC"
      },
      "source": [
        "# Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "9KnRXbHCyfFH"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Image transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # ResNet input images of expects 224x224 pixels\n",
        "    transforms.ToTensor(), #converts image to a format that Pytorch understands\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],  # Imagenet means\n",
        "                         [0.229, 0.224, 0.225])  # Imagenet stds - Rescales pixel values using the average and\n",
        "                         #standard deviation from ImageNet (the dataset ResNet was trained on)\n",
        "])\n",
        "\n",
        "# Paths\n",
        "data_dir = \"/content/split_balanced\"\n",
        "batch_size = 16 #model will process 16 images at a time during training\n",
        "\n",
        "# Loading datasets\n",
        "train_data = datasets.ImageFolder(os.path.join(data_dir, \"train\"), transform=transform)\n",
        "val_data = datasets.ImageFolder(os.path.join(data_dir, \"val\"), transform=transform)\n",
        "test_data = datasets.ImageFolder(os.path.join(data_dir, \"test\"), transform=transform)\n",
        "\n",
        "# DataLoaders\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jMkzNsb0vUT"
      },
      "source": [
        "**torchvision.transforms:** Used to resize, normalize, and convert images to tensors.\n",
        "\n",
        "**datasets.ImageFolder:** Automatically loads images from folders with labels based on subfolder names.\n",
        "\n",
        "**DataLoader:** Helps load the dataset in mini-batches, shuffles data, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5t_eV2sRytDK"
      },
      "source": [
        "# Load and Modify ResNet-50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PP_fNO7Iywhm",
        "outputId": "5ccfe6d6-fc11-4a38-d851-43fb8ee88c17"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet152-394f9c45.pth\" to /root/.cache/torch/hub/checkpoints/resnet152-394f9c45.pth\n",
            "100%|██████████| 230M/230M [00:01<00:00, 121MB/s] \n"
          ]
        }
      ],
      "source": [
        "from torchvision import models\n",
        "import torch.nn as nn\n",
        "\n",
        "# Load pretrained ResNet-50\n",
        "model = models.resnet152(pretrained=True) #loads a ResNet-50 that has already been trained on millions of images (ImageNet)\n",
        "\n",
        "# Freeze earlier layers (optional)\n",
        "#Prevents the earlier layers from being updated while training.\n",
        "#You only train the last fully connected (FC) layer. This is called transfer learning.\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Replace the FC layer for binary classification\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 2)  # 2 classes: yes, no\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtXCVPRvy2Qc"
      },
      "source": [
        "# Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRxvmBZEy4t_",
        "outputId": "ed2f3a8f-36e9-4603-ab52-65649d707ebc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15, Loss: 6.5800, Accuracy: 64.00%\n",
            "Epoch 2/15, Loss: 4.5965, Accuracy: 82.67%\n",
            "Epoch 3/15, Loss: 5.1347, Accuracy: 72.00%\n",
            "Epoch 4/15, Loss: 3.8492, Accuracy: 84.00%\n",
            "Epoch 5/15, Loss: 3.0974, Accuracy: 88.67%\n",
            "Epoch 6/15, Loss: 3.5091, Accuracy: 86.00%\n",
            "Epoch 7/15, Loss: 3.1143, Accuracy: 83.33%\n",
            "Epoch 8/15, Loss: 2.7009, Accuracy: 88.00%\n",
            "Epoch 9/15, Loss: 2.3660, Accuracy: 91.33%\n",
            "Epoch 10/15, Loss: 2.2242, Accuracy: 92.67%\n",
            "Epoch 11/15, Loss: 2.6249, Accuracy: 88.67%\n",
            "Epoch 12/15, Loss: 2.6303, Accuracy: 90.00%\n",
            "Epoch 13/15, Loss: 2.4427, Accuracy: 92.00%\n",
            "Epoch 14/15, Loss: 2.3913, Accuracy: 90.67%\n",
            "Epoch 15/15, Loss: 2.0367, Accuracy: 94.67%\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)  # Only train FC layer\n",
        "\n",
        "# Training loop (basic version)\n",
        "epochs = 15\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct += torch.sum(preds == labels.data)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss:.4f}, Accuracy: {100 * correct/len(train_data):.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CTtnRuQz5Z-"
      },
      "source": [
        "# Validate/Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVESWz_iz7qu",
        "outputId": "46218cf9-be39-4a42-dca7-6cebb9fb8343"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 88.00%\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct += torch.sum(preds == labels.data)\n",
        "\n",
        "print(f\"Test Accuracy: {100 * correct/len(test_data):.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7r3iLGMj0EBr"
      },
      "source": [
        "# Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rt-1_H2N0GVM",
        "outputId": "d72c9f9a-7c2a-4268-d3f0-aa36d44a3aca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 9  3]\n",
            " [ 3 35]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          no       0.75      0.75      0.75        12\n",
            "         yes       0.92      0.92      0.92        38\n",
            "\n",
            "    accuracy                           0.88        50\n",
            "   macro avg       0.84      0.84      0.84        50\n",
            "weighted avg       0.88      0.88      0.88        50\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        outputs = model(images)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.numpy())\n",
        "\n",
        "print(confusion_matrix(all_labels, all_preds))\n",
        "print(classification_report(all_labels, all_preds, target_names=train_data.classes))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtWD2LH43orH"
      },
      "source": [
        "# Save and Load Trained Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCA1EhRV3snD",
        "outputId": "9d5bf113-ad50-4aba-84c5-408464426155"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (6): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (7): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (6): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (7): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (8): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (9): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (10): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (11): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (12): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (13): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (14): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (15): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (16): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (17): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (18): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (19): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (20): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (21): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (22): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (23): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (24): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (25): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (26): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (27): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (28): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (29): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (30): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (31): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (32): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (33): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (34): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (35): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Save the trained model\n",
        "torch.save(model.state_dict(), \"resnet50_brainMRI.pth\")\n",
        "# Recreate the model structure\n",
        "model = models.resnet152(pretrained=True)\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 2)\n",
        "model.load_state_dict(torch.load(\"resnet50_brainMRI.pth\"))\n",
        "model = model.to(device)\n",
        "model.eval()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQbJoIRS32GX"
      },
      "source": [
        "# Visualize Predictions on Test Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "WRP4VAGk35QB"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hBOFOW8138mk"
      },
      "outputs": [],
      "source": [
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))  # from (C, H, W) to (H, W, C)\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean  # unnormalize\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.axis('off')\n",
        "class_names = train_data.classes\n",
        "\n",
        "model.eval()\n",
        "data_iter = iter(test_loader)\n",
        "images, labels = next(data_iter)\n",
        "images = images.to(device)\n",
        "outputs = model(images)\n",
        "_, preds = torch.max(outputs, 1)\n",
        "\n",
        "# Plot the first 4 test images with predictions\n",
        "plt.figure(figsize=(10, 10))\n",
        "for idx in range(4):\n",
        "    ax = plt.subplot(2, 2, idx+1)\n",
        "    imshow(images[idx].cpu())\n",
        "    pred_label = class_names[preds[idx]]\n",
        "    true_label = class_names[labels[idx]]\n",
        "    ax.set_title(f\"Predicted: {pred_label}\\nActual: {true_label}\", fontsize=10)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
